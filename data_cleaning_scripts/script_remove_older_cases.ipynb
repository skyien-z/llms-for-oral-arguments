{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# initialize script variables\n",
    "all_questions_list = []\n",
    "current_justices = [\"John G. Roberts, Jr.\", \"Clarence Thomas\", \"Samuel A. Alito, Jr.\", \"Sonia Sotomayor\", \"Elena Kagan\", \"Neil Gorsuch\", \"Brett M. Kavanaugh\", \"Amy Coney Barrett\", \"Ketanji Brown Jackson\"]\n",
    "\n",
    "def add_questions_from_section(section_json, json_file_name, question_addressee, opening_statement):\n",
    "    '''\n",
    "    Add all questions from transcript section into question list (global var).\n",
    "    Each \"question\" contains metadata of the transcript_id, to whom the question is addressed,\n",
    "    the Supreme Court Justice speaking, and the question text.\n",
    "    '''\n",
    "    turns = section_json[\"turns\"]\n",
    "    for turn in turns:\n",
    "        # 1) check for speaker not existing, 2) inaudible audio, or 3) Elizabeth Prelogar\n",
    "        if turn[\"speaker\"] == None or turn[\"speaker\"][\"roles\"] == None or len(turn[\"speaker\"][\"roles\"]) == 0:\n",
    "            continue\n",
    "        \n",
    "        # check for 1) Justice Amy Coney Barrett or 2) all other justices\n",
    "        if turn[\"speaker\"][\"name\"] in current_justices:\n",
    "            all_text_in_turn =  \" \".join([block[\"text\"] for block in turn[\"text_blocks\"]])\n",
    "            \n",
    "            # check for questions in text turn; use question len > 50 chars as heuristic\n",
    "            if len(all_text_in_turn) > 50 and \"?\" in all_text_in_turn and \"inaudible\" not in all_text_in_turn.lower():\n",
    "                question_info = {}\n",
    "                question_info[\"transcript_id\"] = json_file_name[:-5]\n",
    "                question_info[\"question_addressee\"] = question_addressee\n",
    "                question_info[\"justice\"] = turn[\"speaker\"][\"name\"]\n",
    "                question_info[\"question_text\"] = all_text_in_turn\n",
    "                question_info[\"opening_statement\"] = opening_statement\n",
    "\n",
    "                all_questions_list.append(question_info)\n",
    "\n",
    "\n",
    "def get_formatted_text_of_turn(turn):\n",
    "    '''\n",
    "    Return all text within a turn with xml-like tags denoting speaker and text.\n",
    "    \n",
    "    @param turn -- JSON representing a single speaker turn\n",
    "    @return -- String with xml-like tags\n",
    "    '''\n",
    "    if (turn[\"speaker\"] == None):\n",
    "        return\n",
    "    speaker_in_turn = \"<speaker>\" + turn[\"speaker\"][\"name\"] + \"</speaker>\"\n",
    "    all_text_in_turn = \"<text>\" + \" \".join([block[\"text\"] for block in turn[\"text_blocks\"]]) + \"</text>\"\n",
    "    return speaker_in_turn + all_text_in_turn\n",
    "\n",
    "def add_questions_from_transcript(json_file_name):\n",
    "    '''\n",
    "    Given a transcript, add all justice questions satisfying the criteria in the \n",
    "    data cleaning notes above to our global question list.\n",
    "    '''\n",
    "    with open(TRANSCRIPTS_DIR + json_file_name) as json_file:\n",
    "        transcript_json = json.load(json_file)\n",
    "\n",
    "    sections = transcript_json[\"transcript\"][\"sections\"]\n",
    "    for i in range(len(sections)):\n",
    "        if i % 2 == 0:\n",
    "            question_addressee = \"petitioner\"\n",
    "            petitioner_opening_turn = transcript_json[\"transcript\"][\"sections\"][0][\"turns\"][1]\n",
    "            opening_statement = get_formatted_text_of_turn(petitioner_opening_turn)\n",
    "        else:\n",
    "            question_addressee = \"respondent\"\n",
    "            respondent_opening_turn = transcript_json[\"transcript\"][\"sections\"][1][\"turns\"][0]\n",
    "            opening_statement = get_formatted_text_of_turn(respondent_opening_turn)\n",
    "\n",
    "        add_questions_from_section(sections[i], json_file_name, question_addressee, opening_statement)\n",
    "\n",
    "'''\n",
    "Main function --> goes through all transcripts and add questions to the global list.\n",
    "'''\n",
    "TRANSCRIPTS_DIR = \"../transcripts_up_to_2024/\"\n",
    "FILE_TO_SAVE = \"../datasets/questions_from_current_justices.csv\"\n",
    "\n",
    "for json_file_name in os.listdir(TRANSCRIPTS_DIR):\n",
    "    # ignore hidden files\n",
    "    if json_file_name.startswith('.'):\n",
    "        continue\n",
    "    add_questions_from_transcript(json_file_name)\n",
    "\n",
    "questions_df = pd.DataFrame(all_questions_list)\n",
    "questions_df.to_csv(FILE_TO_SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
