{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fc1440-8ab7-412b-8aba-0b9bddb1d6ec",
   "metadata": {},
   "source": [
    "#### From case briefs and JSON of Cases, make CSV of actual statements made by each justice. For each question, have the justice asking it and the context up to the point of the statement being made (incl. the system prompt)\n",
    "Most code taken from `finetuning-inference-script`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a509712d-847b-46eb-b5bb-36ca17e81ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from datasets import Dataset\n",
    "import re\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "TRANSCRIPTS_DIR = f\"../2024_cases_json/\"\n",
    "CASEBRIEF_DIR = f\"../2023-2024_case_briefs/\"      # directory of raw JSONs of case briefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b67fc-9f0f-46f5-bf6c-c1f24eba8362",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c73cd2-d742-4f06-8b35-e84402da57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if text:\n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        # Replace unicode characters\n",
    "        text = text.replace(\"\\u201c\", \"\\\"\").replace(\"\\u201d\", \"\\\"\").replace(\"\\u2018\", \"'\").replace(\"\\u2019\", \"'\")\n",
    "        return text.strip()\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "def get_facts_and_question(transcript_id, dir=CASEBRIEF_DIR):\n",
    "    case_brief_file_path = os.path.join(dir, transcript_id + \".json\")\n",
    "    with open(case_brief_file_path, 'r') as json_file:\n",
    "        case_brief_json = json.load(json_file)\n",
    "        facts = clean_text(case_brief_json['facts_of_the_case'])\n",
    "        question = clean_text(case_brief_json['question'])\n",
    "        return facts, question\n",
    "\n",
    "def get_system_prompt(transcript_id):\n",
    "    facts, question = get_facts_and_question(transcript_id)\n",
    "    return f\"You are a legal expert trained to simulate Supreme Court oral arguments.\\n\\nFACTS_OF_THE_CASE:\\n{facts}\\n\\nLEGAL_QUESTION:\\n{question}\"\n",
    "\n",
    "def get_formatted_text_of_turn(turn, advocate):\n",
    "    '''\n",
    "    Return all text within a turn as a dict denoting speaker role, and text.\n",
    "\n",
    "    @param turn -- JSON representing a single speaker turn\n",
    "    @return -- Dict with keys \"role\", \"content\"\n",
    "    '''\n",
    "    if not turn[\"speaker\"]:  # skip turns that have no speaker like \"Laughter\"\n",
    "        return None\n",
    "\n",
    "    if not turn[\"speaker\"][\"roles\"]:\n",
    "        role = \"attorney\"\n",
    "    elif ('2' in turn[\"speaker\"][\"roles\"] and turn[\"speaker\"][\"roles\"]['2'][\"type\"] == \"scotus_justice\") or \\\n",
    "         turn[\"speaker\"][\"roles\"][0][\"type\"] == \"scotus_justice\":\n",
    "        role = \"scotus_justice\"\n",
    "\n",
    "    if role == \"scotus_justice\":\n",
    "        identifier = f'justice_{turn[\"speaker\"][\"identifier\"]}'\n",
    "    else:\n",
    "        identifier = advocate\n",
    "\n",
    "    text = \" \".join([block[\"text\"] for block in turn[\"text_blocks\"]])\n",
    "\n",
    "    return {\n",
    "        \"role\": identifier,\n",
    "        \"content\": text\n",
    "    }\n",
    "\n",
    "def get_transcript_data(json_file_name, section):\n",
    "    '''\n",
    "    @param json_file_name -- Name of the oral argument JSON file\n",
    "    @return -- List of dicts with keys \"role\", \"content\" representing each speaker turn in the transcript\n",
    "    '''\n",
    "\n",
    "    transcript_file_path = os.path.join(TRANSCRIPTS_DIR, json_file_name)\n",
    "    with open(transcript_file_path, 'r') as json_file:\n",
    "        transcript_json = json.load(json_file)\n",
    "\n",
    "    formatted_turns = []\n",
    "    advocate = 'respondent' if section else 'petitioner' \n",
    "    section_turns = transcript_json[\"transcript\"][\"sections\"][section][\"turns\"]\n",
    "    section_turns = [get_formatted_text_of_turn(turn, advocate) for turn in section_turns]\n",
    "    section_turns = [turn for turn in section_turns if turn]  # remove None values\n",
    "\n",
    "    return section_turns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bf094-f1ff-4882-b019-6faecc3c9c8c",
   "metadata": {},
   "source": [
    "Load all transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb99150-e68b-4e37-a7af-097f25e991ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "justices = [\n",
    "    \"justice_amy_coney_barrett\",\n",
    "    \"justice_brett_m_kavanaugh\",\n",
    "    \"justice_clarence_thomas\",\n",
    "    \"justice_elena_kagan\",\n",
    "    \"justice_john_g_roberts_jr\",\n",
    "    \"justice_ketanji_brown_jackson\",\n",
    "    \"justice_neil_gorsuch\",\n",
    "    \"justice_samuel_a_alito_jr\",\n",
    "    \"justice_sonia_sotomayor\"\n",
    "]\n",
    "\n",
    "# Load all transcripts\n",
    "data_transcripts = []\n",
    "cases_dir = os.fsencode(TRANSCRIPTS_DIR)\n",
    "for json_file_name in os.listdir(TRANSCRIPTS_DIR):\n",
    "    if json_file_name.endswith('.json'):\n",
    "        for section in [0, 1]:\n",
    "            # Extract the transcript_id\n",
    "            transcript_id = json_file_name[:-9].strip()\n",
    "            try:\n",
    "                # Load the corresponding case brief and extract the facts of the case and the legal question\n",
    "                system_prompt = get_system_prompt(transcript_id)\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system_prompt\n",
    "                    }\n",
    "                ]\n",
    "            except Exception as e:\n",
    "                print(f\"Could not get facts and question from case brief: Skipping {transcript_id}\")\n",
    "                print(e)\n",
    "                continue\n",
    "            # Load the transcript and extract the messages\n",
    "            messages.extend(get_transcript_data(json_file_name, section))\n",
    "            data_transcripts.append({\n",
    "                \"transcript_id\": transcript_id,\n",
    "                \"messages\": messages\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485b68c-b8e8-4249-8578-b17a6eeba41d",
   "metadata": {},
   "source": [
    "Format transcripts into CSV form and save. Remember to apply tokenizer and chat template to the context!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1738c4d4-8793-4fa5-bc63-c78c967f8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = []\n",
    "for transcript in data_transcripts:\n",
    "    context = []\n",
    "    for turn in transcript[\"messages\"]:\n",
    "        if turn[\"role\"] == \"system\" or turn[\"role\"] == \"petitioner\" or turn[\"role\"] == \"respondent\":\n",
    "            context.append(turn)\n",
    "            continue # skip the system prompt\n",
    "        \n",
    "        new_df_row = {\"transcript_id\": transcript[\"transcript_id\"]}\n",
    "        new_df_row[\"context\"] = copy.deepcopy(context)\n",
    "\n",
    "        new_df_row[\"justice\"] = turn[\"role\"]\n",
    "        new_df_row[\"text\"] = turn[\"content\"]\n",
    "        context.append(turn)\n",
    "        context_list.append(new_df_row)\n",
    "\n",
    "df = pd.DataFrame(context_list)\n",
    "df.to_csv(\"generated_data/context_based_statements_format.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d6aeb",
   "metadata": {},
   "source": [
    "Format transcripts into jsonl form and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9bd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "justices = [\n",
    "    \"justice_amy_coney_barrett\",\n",
    "    \"justice_brett_m_kavanaugh\",\n",
    "    \"justice_clarence_thomas\",\n",
    "    \"justice_elena_kagan\",\n",
    "    \"justice_john_g_roberts_jr\",\n",
    "    \"justice_ketanji_brown_jackson\",\n",
    "    \"justice_neil_gorsuch\",\n",
    "    \"justice_samuel_a_alito_jr\",\n",
    "    \"justice_sonia_sotomayor\"\n",
    "]\n",
    "\n",
    "jsonl_path = \"generated_data/context_based_statements_format.jsonl\"\n",
    "with open(jsonl_path, \"w\") as outfile:\n",
    "    for transcript in data_transcripts:\n",
    "        context = []\n",
    "        for turn in transcript[\"messages\"]:\n",
    "            if turn[\"role\"] in [\"system\", \"petitioner\", \"respondent\"]:\n",
    "                context.append(turn)\n",
    "                continue\n",
    "\n",
    "            json_obj = {\n",
    "                \"transcript_id\": transcript[\"transcript_id\"],\n",
    "                \"context\": copy.deepcopy(context),\n",
    "                \"actual_justice\": turn[\"role\"],\n",
    "                \"text\": turn[\"content\"],\n",
    "                \"predictions\": [{justice: {}} for justice in justices]\n",
    "            }\n",
    "\n",
    "            outfile.write(json.dumps(json_obj) + \"\\n\")\n",
    "            context.append(turn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
