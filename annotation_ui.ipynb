{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this interface really simple for now and extensible for later. The main purpose of the interface is to make it easy to manually label our data. To this end, I will read in our JSON file continuously, record user information, and save it. There will be minimal error handling or edge case testing. We assume the user will select the proper results each time. User progress will not be saved. If overrides are needed, please override throught the interface code itself. This is be very jank, but should be fast, simple, and work for our very specific use case.\n",
    "\n",
    "Make continuous annotation_ui file stream. We will assume that the user is keeping track of which annotations they've already made on files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wfy/opt/anaconda3/envs/oral-arg-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker(opening_statement):\n",
    "    return re.findall(r\"<speaker>(.*?)</speaker>\", opening_statement)[0]\n",
    "\n",
    "def get_opening_text(opening_statement):\n",
    "    return re.findall(r\"<text>(.*?)</text>\", opening_statement)[0]\n",
    "\n",
    "def get_text(case_metadata):\n",
    "    return case_metadata.replace(\"<p>\", \"\").replace(\"</p>\", \"\").replace(\"\\n\", \" \")\n",
    "\n",
    "def format_opening_statement(opening_statement):\n",
    "    return f\"**{get_speaker(opening_statement)}** {get_opening_text(opening_statement)}\"\n",
    "\n",
    "def get_year(transcript_id):\n",
    "    return transcript_id[:4]\n",
    "\n",
    "def get_docket(transcript_id):\n",
    "    return transcript_id[5:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BRIEF_TRANSCRIPTS_DIR = \"2023-2024_case_briefs/\"\n",
    "\n",
    "# questions\n",
    "q1_realistic = \"Given the opening statement, is this question realistic for the justice to ask?\"\n",
    "q2_similarity = \"Is this question similar in content to something the justice actually asked?\"\n",
    "q3_valence = \"Is this question similar in valence/sentiment to the justice's actual questions?\"\n",
    "q4_helpfulness = \"If you were preparing this opening statement, would you find this question helpful?\"\n",
    "q5_preference = \"If you were preparing for oral arguments, would you prefer the model's question to the actual question?\"\n",
    "\n",
    "with open('datasets/2024_questions_for_eval.json') as f:\n",
    "    all_data_to_annotate = json.load(f)\n",
    "\n",
    "def get_brief_json(transcript_id):\n",
    "    brief_name = transcript_id[:11] + \".json\"\n",
    "    with open(BRIEF_TRANSCRIPTS_DIR + brief_name) as json_file:\n",
    "        brief_json = json.load(json_file)\n",
    "    return brief_json\n",
    "\n",
    "def generate_markdown(transcript_id, petitioner_or_respondent, justice_name):\n",
    "    selected_data = [x for x in all_data_to_annotate if x[\"transcript_id\"] == transcript_id][0]\n",
    "    advocate_side = selected_data[petitioner_or_respondent.lower()]\n",
    "    transcript_questions = advocate_side[(\"alito\" if justice_name == \"Samuel Alito\" else \"sotomayor\")][\"true_questions\"]\n",
    "    \n",
    "    opening_statement = advocate_side[\"opening_statement\"]\n",
    "    coherent_questions = transcript_questions[0][\"coherent\"]\n",
    "    brief_json = get_brief_json(transcript_id)\n",
    "\n",
    "    return f\"\"\"\n",
    "        # {brief_json[\"name\"]} (Docket {get_docket(transcript_id)}, {get_year(transcript_id)})\n",
    "        ### Facts of the Case\n",
    "        {get_text(brief_json[\"facts_of_the_case\"])}\n",
    "        ### Legal Question\n",
    "        {get_text(brief_json[\"question\"])}\n",
    "        ## {petitioner_or_respondent} {get_speaker(opening_statement)}'s Opening Statement\n",
    "        {get_opening_text(opening_statement)}\n",
    "        ## {justice_name}'s Questions (from the Oral Argument Transcripts)\n",
    "        {\"\\\\\".join([f\"* {get_text(x)}'\" for x in coherent_questions])}\n",
    "        ## LLM-as-{justice_name}'s Questions\n",
    "        Each tab below contains a question generated by a LLM as {justice_name}. Please select the proper annotation\n",
    "        for each survey question. Clicking \"save\" will add your annotation to our database and override any pre-existing \n",
    "        annotations.\n",
    "        \"\"\"\n",
    "\n",
    "def populate_llama_generated_questions(transcript_id, petitioner_or_respondent, justice_name):\n",
    "    selected_transcript = [x for x in all_data_to_annotate if x[\"transcript_id\"] == transcript_id][0]\n",
    "    advocate_side = selected_transcript[petitioner_or_respondent.lower()]\n",
    "    generated_questions = advocate_side[(\"alito\" if justice_name == \"Samuel Alito\" else \"sotomayor\")][\"predicted_questions\"]\n",
    "    llama_generated_questions = generated_questions[0][\"model_questions\"]\n",
    "    return llama_generated_questions\n",
    "\n",
    "def make_likert_scale(question, negation, property, key):\n",
    "    label = f\"{question} (-2 is \\\"Very {negation}\\\" and 2 is \\\"Very {property}\\\")\"\n",
    "    return gr.Radio(range(-2, 3, 1), label=label, key=key)\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Ocean()) as annotation_ui:\n",
    "    generated_questions = gr.State([])\n",
    "    with gr.Column() as config_setup_row:\n",
    "        # initial config set-up\n",
    "        transcript_select_dropdown = gr.Dropdown((x[\"transcript_id\"] for x in all_data_to_annotate), \n",
    "                                                label=\"Select Transcript to Annotate\", interactive=True)\n",
    "        petitioner_or_respondent_select = gr.Radio([\"Petitioner\", \"Respondent\"], label=\"Select Side\", interactive=True)\n",
    "        justice_select = gr.Radio([\"Sonia Sotomayor\", \"Samuel Alito\"], label=\"Select Justice\", interactive=True, visible=False)\n",
    "        question_select_button = gr.Button(value=\"Annotate!\")\n",
    "\n",
    "    with gr.Column(visible=False) as case_info:\n",
    "        transcript_info = gr.Markdown()\n",
    "    \n",
    "        @gr.render(inputs=generated_questions)\n",
    "        def show_split(generated_questions):\n",
    "            for i in range(len(generated_questions)):\n",
    "                with gr.Tab(f\"Question {i + 1}\"):\n",
    "                    gr.Markdown(f\"**Predicted Question**: \\\"{generated_questions[i]}\\\"\")\n",
    "                    is_realistic = gr.Radio([\"Yes\", \"No\"], label=q1_realistic, key=i)\n",
    "                    print(is_realistic.key)\n",
    "                    how_similar = make_likert_scale(q2_similarity, \"Similar\", \"Dissimilar\", i)\n",
    "                    how_sentiment_similar = make_likert_scale(q3_valence, \"Dissimilar in Sentiment\", \"Similar in Sentiment\", i)\n",
    "                    how_helpful = make_likert_scale(q4_helpfulness, \"Unhelpful\", \"Helpful\", i)\n",
    "                    how_prefer = make_likert_scale(q5_preference, \"Prefer the Actual Question\", \"Prefer the Model Question\", i)\n",
    "        submit_button = gr.Button(value=\"Submit Annotation\")\n",
    "\n",
    "    # config set-up interactive logic\n",
    "    petitioner_or_respondent_select.select(fn=lambda: gr.Radio(visible=True), inputs=None, outputs=justice_select)\n",
    "    justice_select.select(fn=lambda: gr.Button(visible=True), inputs=None, outputs=question_select_button)\n",
    "    question_select_button.click(fn=lambda: [gr.Row(visible=False), gr.Column(visible=True)], inputs=None, outputs=[config_setup_row, case_info]).then(\n",
    "        generate_markdown, [transcript_select_dropdown, petitioner_or_respondent_select, justice_select], transcript_info\n",
    "    ).then(\n",
    "        populate_llama_generated_questions, [transcript_select_dropdown, petitioner_or_respondent_select, justice_select], generated_questions\n",
    "    )\n",
    "annotation_ui.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "annotation_ui.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
